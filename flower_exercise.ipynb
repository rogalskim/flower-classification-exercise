{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Make Imports and Set Up Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shutil import copy\n",
    "from os import listdir, makedirs\n",
    "from os.path import isdir, join, splitext\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms as tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 CUDA GPUs available. Using GeForce RTX 2080 SUPER with CUDA 7.5 capability.\n"
     ]
    }
   ],
   "source": [
    "def setup_device() -> torch.device:\n",
    "    if (not torch.cuda.is_available()):\n",
    "        print(\"No CUDA GPUs found. CPU selected as training device.\")\n",
    "        return torch.device(\"cpu\")\n",
    "    \n",
    "    device_id = 0\n",
    "    device = torch.device(f\"cuda:{device_id}\")\n",
    "    count = torch.cuda.device_count()\n",
    "    name = torch.cuda.get_device_name(device_id)\n",
    "    capability = torch.cuda.get_device_capability(device_id)\n",
    "    print(f\"{count} CUDA GPUs available. Using {name} with CUDA {capability[0]}.{capability[1]} capability.\")\n",
    "    return device\n",
    "\n",
    "\n",
    "device = setup_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Divide the Dataset into Categories\n",
    "The used dataset doesn't contain any explicit category labels. However, the source images are sorted by category, with each of the 17 categories having exactly 80 images. Therefore we can label the images by simply counting them. The code assumes the raw images are placed into _data/jpg_ directory. It splits the data into training, validation and testing subsets, then creates a subdirectory for each subset in _data_ dir. In each of those, another set of subdirs is created -- one for each category, named after the category index (0 through 16) and flower images from that category are copied inside. The number of copied files for each subset is defined in the _subset_splits_ dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_file_jpg(file_path: str) -> bool:\n",
    "    path_root, extension = splitext(file_path)\n",
    "    return extension.lower() == \".jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['image_0001.jpg',\n",
       " 'image_0002.jpg',\n",
       " 'image_0003.jpg',\n",
       " 'image_0004.jpg',\n",
       " 'image_0005.jpg',\n",
       " 'image_0006.jpg',\n",
       " 'image_0007.jpg',\n",
       " 'image_0008.jpg',\n",
       " 'image_0009.jpg',\n",
       " 'image_0010.jpg']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data_path = \"data/jpg\"\n",
    "category_count = 17\n",
    "images_per_category = 80\n",
    "\n",
    "# How many images in each category should fall into a data subset\n",
    "subset_splits = {\"training\": 56, \"validation\": 16, \"testing\": 8}\n",
    "assert sum(subset_splits.values()) == images_per_category\n",
    "\n",
    "image_list = [file for file in listdir(raw_data_path) if is_file_jpg(file)]\n",
    "assert len(image_list) == category_count * images_per_category\n",
    "image_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_images_to_categories(category_count: int, images_per_category: int, images: list) -> dict:\n",
    "    categories = {}\n",
    "    for category_index in range(category_count):\n",
    "        first_image_in_category = category_index * images_per_category\n",
    "        last_image_in_category = first_image_in_category + images_per_category\n",
    "        categories[category_index] = images[first_image_in_category:last_image_in_category]\n",
    "    return categories\n",
    "        \n",
    "\n",
    "category_dict = assign_images_to_categories(category_count, images_per_category, image_list)\n",
    "\n",
    "assert len(category_dict.keys()) == category_count\n",
    "assert len(category_dict[category_count - 1]) == images_per_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data_into_subsets(category_dict: dict, subset_splits: dict) -> (dict, dict, dict):\n",
    "    train, valid, test = {}, {}, {}\n",
    "    first_validation_image = subset_splits[\"training\"]\n",
    "    first_testing_image = first_validation_image + subset_splits[\"validation\"]\n",
    "    \n",
    "    for cat_index, cat_images  in category_dict.items():\n",
    "        train[cat_index] = cat_images[:first_validation_image]\n",
    "        valid[cat_index] = cat_images[first_validation_image:first_testing_image]\n",
    "        test[cat_index] = cat_images[first_testing_image:]\n",
    "    \n",
    "    return train, valid, test\n",
    "    \n",
    "    \n",
    "training_images, validation_images, testing_images = split_data_into_subsets(category_dict, subset_splits)\n",
    "\n",
    "assert len(training_images.keys()) == len(validation_images.keys()) == len(testing_images.keys()) == category_count\n",
    "assert len(training_images[10]) == subset_splits[\"training\"]\n",
    "assert len(validation_images[4]) == subset_splits[\"validation\"]\n",
    "assert len(testing_images[16]) == subset_splits[\"testing\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_directory(path: str) -> None:\n",
    "    if not isdir(path):\n",
    "        makedirs(path)\n",
    "        \n",
    "\n",
    "def create_subset_data_directories(subset_dict: dict, subset_name: str, raw_data_path: str) -> None:\n",
    "    subset_dir_path = join(\"data\", subset_name)\n",
    "    create_directory(subset_dir_path)\n",
    "    \n",
    "    for category_index, category_images in subset_dict.items():\n",
    "        category_path = join(subset_dir_path, str(category_index))\n",
    "        create_directory(category_path)\n",
    "        \n",
    "        for image in category_images:\n",
    "            source_path = join(raw_data_path, image)\n",
    "            destination = join(category_path, image)\n",
    "            copy(source_path, destination)\n",
    "        \n",
    "\n",
    "create_subset_data_directories(training_images, \"training\", raw_data_path)\n",
    "create_subset_data_directories(validation_images, \"validation\", raw_data_path)\n",
    "create_subset_data_directories(testing_images, \"testing\", raw_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Pre-process Data and Load into Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The network that will be used in transfer learning has been pre-trained using normalized data. Therefore the same\n",
    "transformation must be performed for new data, for the training to be effective. Below are the values used for original\n",
    "normalization.\n",
    "'''\n",
    "normalization_means = [0.485, 0.456, 0.406]\n",
    "normalization_stds = [0.229, 0.224, 0.225]\n",
    "final_image_size = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "These transformations should help the network to learn translation, rotation and size invariance, to reduce over-training. \n",
    "Additionally they normalize the input data to make it more statistically similar to the data that the network was \n",
    "pre-trained on.\n",
    "'''\n",
    "training_transforms = [tr.RandomRotation(degrees=10, expand=True),\n",
    "                       tr.RandomResizedCrop(size=final_image_size, scale=[0.75, 1.0]),\n",
    "                       tr.ToTensor(),\n",
    "                       tr.Normalize(mean=normalization_means, std=normalization_stds)]\n",
    "\n",
    "testing_transforms = [tr.Resize(size=final_image_size + 8),\n",
    "                      tr.CenterCrop(size=final_image_size),\n",
    "                      tr.ToTensor(),\n",
    "                      tr.Normalize(mean=normalization_means, std=normalization_stds)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "\n",
    "def make_data_loader(data_path: str, transforms: list, batch_size: int) -> DataLoader:\n",
    "    image_transformation = tr.Compose(transforms)\n",
    "    data_set = ImageFolder(root=data_path, transform=image_transformation)\n",
    "    should_pin_memory = torch.cuda.is_available()\n",
    "    loader = DataLoader(dataset=data_set, shuffle=True, pin_memory=should_pin_memory, batch_size=batch_size)\n",
    "    return loader\n",
    "    \n",
    "    \n",
    "training_loader = make_data_loader(\"data/training\", training_transforms, batch_size)\n",
    "validation_loader = make_data_loader(\"data/validation\", training_transforms, batch_size)\n",
    "testing_loader = make_data_loader(\"data/testing\", testing_transforms, batch_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
